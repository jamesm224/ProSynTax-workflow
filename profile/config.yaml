snakefile: workflow/Snakefile
use-conda: True
conda-frontend: mamba
rerun-incomplete: True
jobs: 5
latency-wait: 120
keep-going: True
configfile: inputs/config.yaml
keep-incomplete: False
# unlock: True

cluster: 
  mkdir -p logs/{rule} &&
  sbatch
    --partition={resources.partition}
    --ntasks={resources.tasks}
    --cpus-per-task={resources.cpus_per_task}
    --mem={resources.mem}
    --time={resources.time}
    --job-name={rule}-%j
    --output="logs/{rule}/{wildcards}.out"
    --error="logs/{rule}/{wildcards}.err"

# adjust as needed 
default-resources: 
  - time="1-0"
  - partition="sched_mit_chisholm"
  - mem=12500  # 12.5G
  - cpus_per_task=1  # default threads/CPU/cores
  - tasks=1

set-resources:
  # read trimming (bbduk has threads param but does not fully utilize all cores provide)
  - run_trim_PE:cpus_per_task=4  # 4 cores
  - run_trim_PE:mem=50000  # 50G
  - run_trim_PE:time="1-0"  # 1 days 

  # kaiju (same as read trimming)
  - kaiju_run:cpus_per_task=20  # 20 cores
  - kaiju_run:mem=250000  # 250G
  - kaiju_run:time="4-0"  # 4 days 
